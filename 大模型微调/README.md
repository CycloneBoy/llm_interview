# LLM微调

## [PEFT](/大模型微调/有监督微调.md)

BitFit

Prefix Tuning

Prompt Tuning P-Tuning

P-Tuning v2 Adapter Tuning及其变体

**LoRA**

AdaLoRA

QLoRA 

MAM Adapter

UniPELT

## [RHLF](/大模型微调/强化学习微调.md)

**RHLF**

**PPO**

**DPO**

**GRPO**

**DAPO**

**GRPO相关变体**

## 训练数据


## 参考链接

[DPO vs PPO：深度解读谁是LLM Alignment的未来【不定期更新】](https://zhuanlan.zhihu.com/p/11913305485)
[为什么LLM的主流RLHF算法是PPO? （而不是 SAC, DQN等）](https://zhuanlan.zhihu.com/p/10791831521)
