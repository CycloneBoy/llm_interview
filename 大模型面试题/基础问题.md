# *基础问题*

1. 最新强化学习技术了解什么？
2. Deepseek GRPO，讲讲原理和之后的改进
3. DPO训练原理
4. MOE架构原理
5. Qwen3的技术原理
6. 了解最新技术一般怎么通过什么渠道
7. RAG遇到模型缺失电商知识一般怎么
8. 强化学习的发展历程
9. 多头注意力书写
10. Lora的优势
11. 对话的掩码方式，其次是整体计算？
12. deepspeed zero123区别，有没有看过显存占用
13. grpo比dpo和ppo优势在哪？
14. MLA相比GQA的优势？
15. Agent的看法？
16. 跨模态处理的有效方法？
17. Qwen2-VL的框架介绍？

rag，面试官问我这里是怎么把文本转换成向量储存的。(我以为是问我工程上的实现，这是去年做的一个小模块，回忆了半天细节，答得支支吾吾，面完了之后结合下一个问我才意识到其实是问我embedding过程)

看我支支吾吾就直接问transformer是怎么把token处理成向量的。

transformer的self-attention和cross self-attention区别在哪里。

pre-norm和post-norm的区别？进一步，为什么现在主流大模型都用post-norm。

lora的实现过程。

大模型用的Loss函数是什么(交叉熵)？进一步，使用teaching forcing训练时使用真实标签作为输入，而推理时则是使用模型的输出作为输入，这导致了训练阶段和推理阶段之间的不一致性，为什么会用这个gap。(我在想不是都把原因说出来了吗...这个问题也答得不太好

简述DPO、PPO、GRPO的区别。

问我在读研期间学习后最擅长的技能是什么，我回答数据集构造和强化学习，于是出了一道场景题：如果部门上线的客服机器人，和人工相比不仅语气僵硬而且可能会有不安全回复或者幻觉，如何解决？(感觉答得也不太好，一面之后稍微了解了下客服机器人的内容，但是答得太浅了)

.attention的计算公式
追问：为什么除根号dk

3.bert和gpt了解吗(only encoder/decoder)

4.lora原理

5.模型蒸馏

6.用过哪些微调

7.BN和LN的区别

8.过拟合怎么处理

9.数据不平衡怎么处理
项目:深挖八股Transformer 结构和 LSTM 的区别和优势，Transformer 怎么体现时序信息？
3️⃣Transformer Encoder 和 Decoder 的输入输出和结构BatchNorm 更多用在视觉上，LayerNorm 更多用在语言上，为什么有没 chatGLM，LLaMA 等部署、微调经历？
4️⃣有没有了解过大模型加速推理？
5️⃣讲一下 Flash Attention?

. crf的转移矩阵和发射矩阵是什么？计算公式和计算结果是什么？

1. 大模型微调怎么做的？
2. Qwen的位置编码是怎么做的（rope和YaRN）
3. rope是加上去的还是乘上去的？bert的呢
4. rope是怎么应用在超出长度限制的输入上的，bert的位置编码可以用到超出长度限制的输入上吗
5. 如果大模型输入是4k长度，可以输出8k的长度输出吗
6. lora可以用在哪些地方？为什么可以用在ffn层？为什么作者一开始先用在q,k,v,o的权重矩阵上？
7. 如何理解低秩状态？
8. Lora原理以及初始化
9. Lora参数含义
10. Deepspeed三阶段
11. 强化学习框架
12. PPO，DPO，GRPO
13. PPO的critic model作用
14. 大模型温度系数作用，topk和p的区别
15. bert的位置编码以及ROPE
16. 深入探讨Deepseek的技术
17. 深入探讨MOE和Dense模型

4.微调的显存需求，如何估算？经典的Deepspeed举例
5.deepspeed 原理 （ZeRO三阶段、offload）

. Transformer的原理

1. 过拟合的解决方案有哪些
2. PPO和DPO的优劣势
3. ERNIE 相较于 Bert 的不同
4. 各类位置编码的优劣势
5. Deepspeed的三阶段
6. RNN的缺点以及变体的优势
7. 讲解LoRA原理

3.模型训练过程loss飙升的原因
4.介绍dpo算法原理，训练过程需要注意的地方
5.介绍并对比LLM的三种架构
6.大模型的词表生成方法，BPE的缺点是什么

. deepspeed框架介绍

1. lora介绍，了解什么其他高效微调方法
2. prompt tuning, instruct tuning, fine tuning差别
3. llama中per norm，rmsnorm的介绍，优劣，position embedding构造方法
4. prompt构造经验，怎样的prompt更好

. 深挖实习和项目，直到你不会的

1. 位置编码有哪几种？具体介绍了ROPE
2. 跨模态对齐的方案有哪些？为什么选择该方案
3. 针对长序列问题建模你有什么见解？
4. DPO的公式以及原理？
5. RAG中你认为的关键点有哪些？并就其中1-2点展开下
6. 聊一聊大模型的发展道路？
7. 为什么分类用CE不用 MSE？
8. 残差网络的优点，至少说出3个
9. Deepspeed的三阶段介绍下
10. 介绍下LLAMA的架构
11. 代码题：MHA，岛屿最大面积，还有个忘了

.adam优化器原理
3.LLama框架和transformer框架的主要区别，以及其中的归一化操作是什么，怎样实现的
4.lora的实现原理，其他微调方法.大语言模型量化、蒸馏、剪枝操作如何实现
5.旋转位置编码的原理
6.手撕多头注意力机制

3、cot怎么做的
4、rag怎么做的
5、deepseek了解吗，moe和grpo讲一下(没看，不会)

RL的reward设计原理，为何这样设计

1. 讲讲 LoRA 微调。
2. 手撕：Multi-Head Attention (MHA)。
3. MHA 里面除以根号 k 是干嘛的？
4. 什么是梯度消失和梯度爆炸？怎么缓解？
5. QKV 分别代表什么？说说你的理解。
6. 如果 Q 和 K 变成同一个矩阵，会有什么影响？
7. 除了 LoRA，还知道哪些微调方法？



ppo的损失函数grpo的原理

如何抽取简历：大段的文本如何抽取

生成不一致如何缓解

生成复读机如何解决

#### Deepseek v3 和其他qwen2.5的架构区别：

 多头潜在注意力机制 (MLA) 

Mixture-of-Experts (MoE)

DeepSeek-V3开创了采用**专家选择辅助无损失函数（auxiliary-loss-free strategy**，在不实用采样loss帮助下，让每个专家访问次数接近）的负载均衡策略和**多令牌预测（multi-token prediction，每次预测多个token）**训练

让每个路由专家被选中的概率接近**多token预测（multi-token prediction）**，有利于一次性预测多个，目的是建立辅助loss，让模型有一次性考虑多个未来token的能力，同时可以用于推理加速的推测解码。


Deepseek r1

dapo 的优化

论文的亮点在哪里

sql生成 schema是如何放的，有什么方式召回字段

一句话描述一下q,k,v



Deepseek r1是如何训练出来的

qwen3

Moe模型为啥